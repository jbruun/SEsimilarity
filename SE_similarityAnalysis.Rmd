---
title: "Similarity network analyses of self-efficacy attributes"
author: "Jesper Bruun"
date: "3/12/2020"
output: github_document
---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Description


```{r libraries_and_functions}
library(igraph)
library(PMCMRplus)
library(effsize)
#library(rcompanion)
library(gplots)
source("R_scripts/backboneExtraction.r")
source("R_scripts/segregation.r")
```

## Load data
```{r load-data}
mydata<-read.csv("Data/dataset.csv",sep=";")
mydata$X<-c(1:length(mydata$Name))
```

## Make respondent similarity networks
```{r make-networks}
  #Name respondents
resp<-paste("R",c(1:length(mydata$X)),sep="") 
  #Function for calculating frequencies (here equated with probabilities) of responses
probs<-function(mydata,n){
  a<-as.numeric(names(table(mydata[,n])))
  p<-as.numeric(table(mydata[,n],useNA = "always")/length(resp))
  x<-c(1:length(resp))
  for(i in 1:length(a)){
    x[which(mydata[,n]==a[i])]<-p[i]
  }
  x[which(is.na(mydata[,n]))]<-p[6]
  return(x)
}
  #Identify which columns contain pre and which contain post responses. 
names(mydata[3:14]) #Columns for pre
names(mydata[15:26]) #Columns for post
post<-mydata[15:26] #Responses to post survey questions
post[is.na(post)]<-100 #R does not like to perform calculations with NAs
pre<-mydata[3:14] # We will compare pre community structure with post community structure
pre[is.na(pre)]<-100


  #Function which transforms frequencies/probabilities to information (bits)
pmat<-function(data){
pmat<-matrix(0,ncol=length(data),nrow=length(data[,1]))
for(j in 1:length(data)){
  pmat[,j]<-probs(data,j)  
  
}
infmat<--log2(pmat)
return(infmat)
}

  #Function for calculating similarities between respondents
  #The function uses Lin's (1998) information theoretical measure. 
simRes<-function(i,j,infmat,d){
  y<-infmat[i,]
  overlap<-sum(y[which(d[i,1:12]==d[j,1:12])])
  sinfi<-sum(infmat[i,])
  sinfj<-sum(infmat[j,])
  sim<-2*overlap/(sinfi+sinfj)
  return(sim)
}

  #Function for calculating similarity between k'th respondent and everyone else
simResk<-function(k,inf,d){
    simVec<-vector()
  for(i in 1:length(resp)){
    simVec[i]<-simRes(k,i,inf,d)
  }
  return(simVec)
}

  #Function for making similarity matrix. 
simMatrix<-function(d){
  inf<-pmat(d)
  similarityMatrix<-matrix(data=0,ncol=length(d[,1]),nrow=length(d[,1]))
  for(i in 1:length(resp)){
    similarityMatrix[,i]<-simResk(i,inf,d)  
    
  }
  return(similarityMatrix)
}

  #Functions are now used to create a post similarity network
postSim<-simMatrix(post)
respTot<-resp
respT<-resp[mydata$control=="n"]
respC<-resp[mydata$control=="y"]

resp<-respT
preSimT<-simMatrix(pre[mydata$control=="n",])
postSimT<-simMatrix(post[mydata$control=="n",])

preNetT<-graph.adjacency(preSimT,diag=F,weighted=T)
postNetT<-graph.adjacency(postSimT,diag=F,weighted=T)
V(preNetT)$id<-respT
V(postNetT)$id<-respT

#Extract backbone networks
preNetBBT<-backboneNetwork(preNetT,0.0176,2) #Alpha value set to minimum value that keeps the network connected
postNetBBT<-backboneNetwork(postNetT,0.0335,2)# This is the network we focus on in the article.

write.graph(postNetBBT,"postNetBBT.net",format=c("pajek"))
write.graph(preNetBBT,"preNetBBT.net",format=c("pajek"))

plot(postNetT)
plot(postNetBBT)
```

##Infomap clustering
```{r infomap-clusering}
#1000 infomaps
#CODE FOR WRITING 1000 INFOMAPS IN INFOMAP FOLDER:
#for i in {1..1000}; do ./pathToNetwork/[name].net /pathtoFolder/1000Infomaps[name]/
#--out-name $i -2 --clu --map -s$i; done

files<-vector()
for (i in 1:1000){
  files[i]<-paste("Data/1000InfomapsPreBBT/",i,".clu",sep = "")
  
}
#setwd("..") #go to where the files are
csvs<-lapply(files,read.csv,skip=2,header=F,sep="")

a<-matrix(data=0,nrow=1000,ncol=64)
for (i in 1:1000){
  a[i,]<-csvs[[i]][ order(csvs[[i]][,1]),2 ]
  
}

comp<-function(j){
  nmi<-vector()
  for(i in 1:1000){
    nmi[i]<-compare(a[i,],a[j,],method="nmi")  
    
  }
  return(nmi)  
} 

nmiM<-matrix(data=0,nrow=1000,ncol=1000)
for(i in 1:1000){
  nmiM[i,]<-comp(i)
  
}

mean(nmiM) #Normalized mutual information of pre-cluster solutions
sd(nmiM) #Standard deviation of NMI

files<-vector()
for (i in 1:1000){
  files[i]<-paste("Data/1000InfomapsPostBBT/",i,".clu",sep = "")
  
}
#setwd("..") #go to where the files are
csvs<-lapply(files,read.csv,skip=2,header=F,sep="")

a<-matrix(data=0,nrow=1000,ncol=64)
for (i in 1:1000){
  a[i,]<-csvs[[i]][ order(csvs[[i]][,1]),2 ]
  
}

comp<-function(j){
  nmi<-vector()
  for(i in 1:1000){
    nmi[i]<-compare(a[i,],a[j,],method="nmi")  
    
  }
  return(nmi)  
} 

nmiM<-matrix(data=0,nrow=1000,ncol=1000)
for(i in 1:1000){
  nmiM[i,]<-comp(i)
  
}

mean(nmiM)#Normalized mutual information of post-cluster solutions
sd(nmiM)#Standard deviation of NMI

#Compare pre to post groupings
#Get most frequent groupings
postBBTgroup<-read.csv("Data/1000InfomapsPostBBT/1.clu",skip=2,header=F,sep="") #for us it was the first grouping.
postBBTgroup<-postBBTgroup[order(postBBTgroup$V1),]
preBBTgroup<-read.csv("Data/1000InfomapsPreBBT/2.clu",skip=2,header=F,sep="") #for us it was the first grouping.
preBBTgroup<-preBBTgroup[order(preBBTgroup$V1),]
compare(preBBTgroup$V2,postBBTgroup$V2,method="nmi") 

```
## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
